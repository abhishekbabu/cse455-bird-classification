{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, random_split\n\nimport torchvision\nfrom torchvision import datasets, models, transforms\n\nimport matplotlib.pyplot as plt\n\nimport copy\nimport os\nimport time\n\ncudnn.benchmark = True","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-05T19:04:29.181977Z","iopub.execute_input":"2022-06-05T19:04:29.182352Z","iopub.status.idle":"2022-06-05T19:04:29.189646Z","shell.execute_reply.started":"2022-06-05T19:04:29.182311Z","shell.execute_reply":"2022-06-05T19:04:29.187864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Constants\nVAL_SIZE = 0.1\nTEST_SIZE = 0.1\nSEED = 455","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:04:33.025719Z","iopub.execute_input":"2022-06-05T19:04:33.026113Z","iopub.status.idle":"2022-06-05T19:04:33.030539Z","shell.execute_reply.started":"2022-06-05T19:04:33.026083Z","shell.execute_reply":"2022-06-05T19:04:33.029343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(SEED)\nnp.random.seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:04:37.426223Z","iopub.execute_input":"2022-06-05T19:04:37.426692Z","iopub.status.idle":"2022-06-05T19:04:37.436893Z","shell.execute_reply.started":"2022-06-05T19:04:37.426652Z","shell.execute_reply":"2022-06-05T19:04:37.435943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:04:39.799579Z","iopub.execute_input":"2022-06-05T19:04:39.800041Z","iopub.status.idle":"2022-06-05T19:04:39.809072Z","shell.execute_reply.started":"2022-06-05T19:04:39.800002Z","shell.execute_reply":"2022-06-05T19:04:39.808009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/rice-image-dataset/Rice_Image_Dataset'","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:04:41.29679Z","iopub.execute_input":"2022-06-05T19:04:41.297218Z","iopub.status.idle":"2022-06-05T19:04:41.304077Z","shell.execute_reply.started":"2022-06-05T19:04:41.29718Z","shell.execute_reply":"2022-06-05T19:04:41.303269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create datasets\nimage_dataset = datasets.ImageFolder(data_dir, transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n]))","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:04:42.796614Z","iopub.execute_input":"2022-06-05T19:04:42.797485Z","iopub.status.idle":"2022-06-05T19:04:58.841127Z","shell.execute_reply.started":"2022-06-05T19:04:42.797448Z","shell.execute_reply":"2022-06-05T19:04:58.840317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(image_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:04:58.842661Z","iopub.execute_input":"2022-06-05T19:04:58.843022Z","iopub.status.idle":"2022-06-05T19:04:58.848397Z","shell.execute_reply.started":"2022-06-05T19:04:58.842988Z","shell.execute_reply":"2022-06-05T19:04:58.847159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_length = int(len(image_dataset) * VAL_SIZE)\ntest_length = int(len(image_dataset) * TEST_SIZE)\ntrain_length = len(image_dataset) - (val_length + test_length)\ntrain_dataset, val_dataset, test_dataset = random_split(image_dataset, [train_length, val_length, test_length])","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:04.411377Z","iopub.execute_input":"2022-06-05T19:05:04.411984Z","iopub.status.idle":"2022-06-05T19:05:04.424785Z","shell.execute_reply.started":"2022-06-05T19:05:04.411951Z","shell.execute_reply":"2022-06-05T19:05:04.423975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_datasets = {\n    'train': train_dataset,\n    'val': val_dataset,\n    'test': test_dataset\n}\ndataset_sizes = { x: len(image_datasets[x]) for x in ['train', 'val', 'test'] }","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:06.812555Z","iopub.execute_input":"2022-06-05T19:05:06.812906Z","iopub.status.idle":"2022-06-05T19:05:06.817806Z","shell.execute_reply.started":"2022-06-05T19:05:06.812877Z","shell.execute_reply":"2022-06-05T19:05:06.816834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = { x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=x!='test', num_workers=2)\n              for x in ['train', 'val', 'test'] }","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:08.289499Z","iopub.execute_input":"2022-06-05T19:05:08.290131Z","iopub.status.idle":"2022-06-05T19:05:08.306139Z","shell.execute_reply.started":"2022-06-05T19:05:08.290093Z","shell.execute_reply":"2022-06-05T19:05:08.305336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = image_datasets['train'].dataset.classes\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:10.539405Z","iopub.execute_input":"2022-06-05T19:05:10.54015Z","iopub.status.idle":"2022-06-05T19:05:10.54492Z","shell.execute_reply.started":"2022-06-05T19:05:10.540113Z","shell.execute_reply":"2022-06-05T19:05:10.543925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:15.806705Z","iopub.execute_input":"2022-06-05T19:05:15.807135Z","iopub.status.idle":"2022-06-05T19:05:15.813106Z","shell.execute_reply.started":"2022-06-05T19:05:15.807104Z","shell.execute_reply":"2022-06-05T19:05:15.812269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from the batch\nout = torchvision.utils.make_grid(inputs[:4])\n\n# Display the images\nimshow(out, title=[class_names[x] for x in classes[:4]])\nplt.savefig('Examples.png')","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:46.443987Z","iopub.execute_input":"2022-06-05T19:05:46.444363Z","iopub.status.idle":"2022-06-05T19:05:46.855439Z","shell.execute_reply.started":"2022-06-05T19:05:46.444329Z","shell.execute_reply":"2022-06-05T19:05:46.853507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n\n    for epoch in range(num_epochs):\n        epoch_start = time.time()\n\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            if phase == 'train':\n                train_losses.append(epoch_loss)\n                train_accuracies.append(epoch_acc)\n            else:\n                val_losses.append(epoch_loss)\n                val_accuracies.append(epoch_acc)\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        epoch_time = time.time() - epoch_start\n        print(f'Epoch time: {epoch_time // 60:.0f}m {epoch_time % 60:.0f}s')\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, train_losses, val_losses, train_accuracies, val_accuracies","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:29.447366Z","iopub.execute_input":"2022-06-05T19:05:29.447723Z","iopub.status.idle":"2022-06-05T19:05:29.461733Z","shell.execute_reply.started":"2022-06-05T19:05:29.447691Z","shell.execute_reply":"2022-06-05T19:05:29.460773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title(f'predicted: {class_names[preds[j]]}')\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:05:59.923107Z","iopub.execute_input":"2022-06-05T19:05:59.923496Z","iopub.status.idle":"2022-06-05T19:05:59.933152Z","shell.execute_reply.started":"2022-06-05T19:05:59.923462Z","shell.execute_reply":"2022-06-05T19:05:59.932229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_accuracy(model):\n    correct = 0\n    \n    with torch.no_grad():\n        for inputs, labels in dataloaders['test']:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            correct += torch.sum(preds == labels.data)\n    \n    accuracy = correct.double() / dataset_sizes['test']\n    \n    print(f'Test accuracy: {accuracy:4f}')\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:06:01.885795Z","iopub.execute_input":"2022-06-05T19:06:01.886144Z","iopub.status.idle":"2022-06-05T19:06:01.892807Z","shell.execute_reply.started":"2022-06-05T19:06:01.886114Z","shell.execute_reply":"2022-06-05T19:06:01.891942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet18 with SGD","metadata":{}},{"cell_type":"code","source":"resnet1 = torchvision.models.resnet18(pretrained=True)\nfor param in resnet1.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = resnet1.fc.in_features\nresnet1.fc = nn.Linear(num_ftrs, len(class_names))\n\nresnet1 = resnet1.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer = optim.SGD(resnet1.fc.parameters(), lr=0.01, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:06:06.538369Z","iopub.execute_input":"2022-06-05T19:06:06.538718Z","iopub.status.idle":"2022-06-05T19:06:11.868167Z","shell.execute_reply.started":"2022-06-05T19:06:06.53869Z","shell.execute_reply":"2022-06-05T19:06:11.867348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet1, r1_train_loss, r1_val_loss, r1_train_acc, r1_val_acc = train_model(\n    resnet1, criterion, optimizer, exp_lr_scheduler, num_epochs=25)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:06:35.508625Z","iopub.execute_input":"2022-06-05T19:06:35.508985Z","iopub.status.idle":"2022-06-05T21:03:06.215321Z","shell.execute_reply.started":"2022-06-05T19:06:35.508957Z","shell.execute_reply":"2022-06-05T21:03:06.213646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nplt.plot(r1_train_loss, label='Training Loss')\nplt.plot(r1_val_loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Cross Entropy Loss for ResNet18 with SGD')\nplt.savefig('ResNet18 SGD Loss.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:03:06.217456Z","iopub.execute_input":"2022-06-05T21:03:06.218016Z","iopub.status.idle":"2022-06-05T21:03:06.468896Z","shell.execute_reply.started":"2022-06-05T21:03:06.217971Z","shell.execute_reply":"2022-06-05T21:03:06.468111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nplt.plot([acc.cpu() for acc in r1_train_acc], label='Training Accuracy')\nplt.plot([acc.cpu() for acc in r1_val_acc], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Accuracy for ResNet18 with SGD')\nplt.savefig('ResNet18 SGD Accuracy.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:03:06.470023Z","iopub.execute_input":"2022-06-05T21:03:06.470433Z","iopub.status.idle":"2022-06-05T21:03:06.718023Z","shell.execute_reply.started":"2022-06-05T21:03:06.470398Z","shell.execute_reply":"2022-06-05T21:03:06.717152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(resnet1.state_dict(), 'resnet1.pth')","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:03:06.720007Z","iopub.execute_input":"2022-06-05T21:03:06.720393Z","iopub.status.idle":"2022-06-05T21:03:06.817113Z","shell.execute_reply.started":"2022-06-05T21:03:06.720356Z","shell.execute_reply":"2022-06-05T21:03:06.816182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(resnet1)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:03:06.818681Z","iopub.execute_input":"2022-06-05T21:03:06.819263Z","iopub.status.idle":"2022-06-05T21:03:07.621715Z","shell.execute_reply.started":"2022-06-05T21:03:06.819219Z","shell.execute_reply":"2022-06-05T21:03:07.6208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r1_test_accuracy = get_test_accuracy(resnet1)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:03:07.62313Z","iopub.execute_input":"2022-06-05T21:03:07.623577Z","iopub.status.idle":"2022-06-05T21:03:53.186836Z","shell.execute_reply.started":"2022-06-05T21:03:07.623536Z","shell.execute_reply":"2022-06-05T21:03:53.185764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet18 with Adadelta","metadata":{}},{"cell_type":"code","source":"resnet2 = torchvision.models.resnet18(pretrained=True)\nfor param in resnet2.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = resnet2.fc.in_features\nresnet2.fc = nn.Linear(num_ftrs, len(class_names))\n\nresnet2 = resnet2.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer = optim.Adadelta(resnet2.fc.parameters(), lr=0.01)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet2, r2_train_loss, r2_val_loss, r2_train_acc, r2_val_acc = train_model(\n    resnet2, criterion, optimizer, exp_lr_scheduler, num_epochs=25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nplt.plot(r2_train_loss, label='Training Loss')\nplt.plot(r2_val_loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Cross Entropy Loss for ResNet18 with Adadelta')\nplt.savefig('ResNet18 Adadelta Loss.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nplt.plot([acc.cpu() for acc in r2_train_acc], label='Training Accuracy')\nplt.plot([acc.cpu() for acc in r2_val_acc], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Accuracy for ResNet18 with Adadelta')\nplt.savefig('ResNet18 Adadelta Accuracy.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(resnet2.state_dict(), 'resnet2.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(resnet2)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r2_test_accuracy = get_test_accuracy(resnet2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResNet18 with RMSprop","metadata":{}},{"cell_type":"code","source":"resnet3 = torchvision.models.resnet18(pretrained=True)\nfor param in resnet3.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = resnet3.fc.in_features\nresnet3.fc = nn.Linear(num_ftrs, len(class_names))\n\nresnet3 = resnet3.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer = optim.RMSprop(resnet3.fc.parameters(), lr=0.01, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet3, r3_train_loss, r3_val_loss, r3_train_acc, r3_val_acc = train_model(\n    resnet3, criterion, optimizer, exp_lr_scheduler, num_epochs=25)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nplt.plot(r3_train_loss, label='Training Loss')\nplt.plot(r3_val_loss, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Cross Entropy Loss for ResNet18 with RMSprop')\nplt.savefig('ResNet18 RMSprop Loss.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 4))\nplt.plot([acc.cpu() for acc in r3_train_acc], label='Training Accuracy')\nplt.plot([acc.cpu() for acc in r3_val_acc], label='Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Accuracy for ResNet18 with RMSprop')\nplt.savefig('ResNet18 RMSprop Accuracy.png')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(resnet3.state_dict(), 'resnet3.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(resnet3)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r3_test_accuracy = get_test_accuracy(resnet3)","metadata":{},"execution_count":null,"outputs":[]}]}